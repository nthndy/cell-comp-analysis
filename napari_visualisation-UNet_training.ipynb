{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAPARI visualization of UNet Training Data\n",
    "\n",
    "You can use this notebook to view, modified and save out training data for UNet models\n",
    "\n",
    "Labels:\n",
    "+ 0 - background \n",
    "+ 1 - GFP/Phase \n",
    "+ 2 - RFP\n",
    "\n",
    "\n",
    "Extra key bindings:\n",
    "+ 'w' - calculate weightmap\n",
    "+ 'q' - calculate custom annotated weightmap (weightmask * weightmap)\n",
    "+ '/' - save label current displayed\n",
    "+ 's' - save all labels\n",
    "+ 'o' - output all weightmaps and metadata for tfrecord creation\n",
    "+ '\\>' - grow the label under the mouse cursor\n",
    "+ '\\<' - shrink the label under the mouse cursor\n",
    "+ 'h' - fill holes in cell mask under the mouse cursor\n",
    "+ 'n' - count cells (will be updated to collect more stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "```\n",
    "Authors:\n",
    "- Alan R. Lowe (a.lowe@ucl.ac.uk)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Set up the data path, channel(s) used, weight amplitude and the number of images to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/nathan/analysis/training/training_data'\n",
    "#DATA_PATH = '/home/nathan/analysis/fucci/working_dir/all/full_stack'\n",
    "\n",
    "WEIGHT_AMPLITUDE = 50.\n",
    "ACQUISITION_CHANNELS = ['PHASE'] #complete sets\n",
    "INCOMPLETE_CHANNELS = ['GFP'] #, 'RFP', 'IRFP'] #list here if sets incomplete ie some images missing\n",
    "NUMBER_OF_IMAGES_TO_LOAD = 1 #'ALL' #in each set, from index 0, loads in numerical order, if all images desired then enter 'ALL'\n",
    "INDEX_OF_IMAGES = [1053, 1093] #enter [min, max] and ensure NUMBER_OF_IMAGES_TO_LOAD = 0\n",
    "#INDEX_OF_IMAGES = [minimum:maximum]\n",
    "#ACQUISITION_CHANNELS = ['GFP', 'RFP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import enum\n",
    "import json\n",
    "import csv\n",
    "import napari\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from skimage.util import random_noise\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from itertools import islice\n",
    "\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@enum.unique\n",
    "class Channels(enum.Enum):\n",
    "    BRIGHTFIELD = 0 \n",
    "    GFP = 1\n",
    "    RFP = 2\n",
    "    IRFP = 3\n",
    "    PHASE = 4\n",
    "    WEIGHTS = 98\n",
    "    MASK = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global filename\n",
    "#global files\n",
    "\n",
    "\n",
    "\n",
    "def strip_modified_filename(filename):\n",
    "    if filename.endswith('.modified.tif'):\n",
    "        stripped_fn = filename[:-len('.modified.tif')]\n",
    "        return stripped_fn\n",
    "    return filename\n",
    "\n",
    "def make_folder(foldername):\n",
    "    if os.path.exists(foldername):\n",
    "        return\n",
    "    os.mkdir(foldername)\n",
    "    \n",
    "def file_root(filename):  #searches for the filename pattern inside the given filename, returns the result of that search as grps\n",
    "    FILENAME_PATTERN = r'([a-zA-Z0-9]+)_([a-zA-Z0-9]+)_*.tif'\n",
    "    grps = re.search(FILENAME_PATTERN, filename)\n",
    "    return grps\n",
    "\n",
    "def load_training_data(pth, channels=[Channels.GFP, Channels.RFP]):\n",
    "    \"\"\" load training data for visualisation with napari\"\"\"\n",
    "          \n",
    "    # find the sets and sort them\n",
    "    global sets #allows sets to be called from another function\n",
    "    sets = [f for f in os.listdir(pth) if os.path.isdir(os.path.join(pth, f))]\n",
    "    sets.sort(key = lambda s: int(s[3:]))\n",
    "    \n",
    "    def set_filename_format(filename): #both functions below serve to find filenames regardless of x_gfp.tif or gfp_x.tif\n",
    "        grps = file_root(filename)\n",
    "        \n",
    "        if grps.group(1) in [c.name.lower() for c in all_channels]: #if a feature about the fn pattern is in the channel name (ie gfp) then FNFMT = 2, allowing for x_gfp.tif or gfp_x.tif to be sorted \n",
    "            FILENAME_FORMAT = 2 #gfp_x.tif\n",
    "        else:\n",
    "            FILENAME_FORMAT = 1 #x_gfp.tif\n",
    "            \n",
    "        def filename_formatter(filename, channel):\n",
    "            # assert(channel in [c.name.lower() for c in all_channels])\n",
    "            grps = file_root(filename)\n",
    "\n",
    "            return f'{grps.group(FILENAME_FORMAT)}_{channel}.tif'\n",
    "            # return '{}_{}.tif'.format(*[channel, grps.group(FILENAME_FORMAT)])\n",
    "        \n",
    "        return filename_formatter\n",
    "    \n",
    "    global label_files\n",
    "    global fnfmt\n",
    "    global files\n",
    "    \n",
    "    all_channels = [Channels.MASK, Channels.WEIGHTS]+channels\n",
    "    files = {k:{'files':[], 'data':[], 'sets':[], 'path':[]} for k in all_channels}\n",
    "    all_channels.remove(Channels.WEIGHTS)\n",
    "       \n",
    "    for s in sets:\n",
    "\n",
    "        # root_folders\n",
    "        l_root = os.path.join(pth, s, 'labels')\n",
    "        \n",
    "        # check that this folder exists \n",
    "        if not os.path.exists(l_root):\n",
    "            raise IOError(f'{l_root} does not exist. Do you need to rename label -> labels?')\n",
    "\n",
    "        # get the training label files\n",
    "        label_files = [f for f in os.listdir(l_root) if f.endswith('.tif')]\n",
    "        #print(label_files)\n",
    "        \n",
    "        # sort to remove unmodified files and replace with the modified files\n",
    "        unmodified_files, modified_files = [], []\n",
    "        \n",
    "        #for index, item in enumerate(islice(items, limit)):\n",
    "        for i, f in enumerate(label_files): #introducing islice here allows you to choose size of dataset! but only in a random order\n",
    "            if f.endswith('.modified.tif'):\n",
    "                modified_files.append(strip_modified_filename(f))\n",
    "            else:\n",
    "                unmodified_files.append(f)\n",
    "                \n",
    "        unmodified_files = list(set(unmodified_files).difference(set(modified_files))) #this is only unmod where mod doesnt exist\n",
    "        label_files_full = unmodified_files + [f+'.modified.tif' for f in modified_files]    \n",
    "        label_files_full.sort(key = lambda f: int(f[0:4])) #sorts files numerically\n",
    "\n",
    "        N = NUMBER_OF_IMAGES_TO_LOAD\n",
    "        n = INDEX_OF_IMAGES[0]\n",
    "        m = INDEX_OF_IMAGES[1]\n",
    "                \n",
    "        if N == 'ALL':\n",
    "            label_files = label_files_full\n",
    "        elif N > 0:\n",
    "            label_files = label_files_full[:N] #cuts list of files to N images\n",
    "        else:\n",
    "            label_files = label_files_full[n:m] #cuts list of files to n->m images       \n",
    "        ## MAKE THIS ELIF TIDIER SO ONLY ONE INPUT IS REQUIRED ##        \n",
    "        \n",
    "        fnfmt = set_filename_format(label_files[0]) #why only label_files[0]? -> bc only need one example to set the fnfmt\n",
    "                        \n",
    "        files[Channels.MASK]['path'] += [s+'/labels/'+f for f in label_files]\n",
    "        files[Channels.MASK]['files'] += [strip_modified_filename(f) for f in label_files]\n",
    "        files[Channels.MASK]['data'] += [io.imread(os.path.join(l_root, f)) for f in label_files]\n",
    "        files[Channels.MASK]['sets'] += [s] * len(label_files)\n",
    "        \n",
    "        for channel in channels:\n",
    "            \n",
    "           #if cfiles channel.name.lower dir doesnt contain gfp or rfp then add option to create noise data,\n",
    "            channel_dir = os.path.join(pth, s, channel.name.lower())            \n",
    "            #if os.path.exists(channel_dir): #if fluor/phase channels exist, continue as norm\n",
    "            cfiles = [fnfmt(l, channel.name.lower()) for l in label_files]\n",
    "            files[channel]['path'] += [s+'/'+channel.name.lower()+'/'+f for f in cfiles]\n",
    "            files[channel]['files'] += cfiles #filenames\n",
    "            files[channel]['data'] += [io.imread(os.path.join(pth, s, channel.name.lower(), f)) for f in cfiles] #actualdata\n",
    "            files[channel]['sets'] += [s] * len(label_files)\n",
    "            \n",
    "            \"\"\"else: #if fluor ch missing then create one and fill it with noise - should add this to separate func later\n",
    "                os.mkdir(channel_dir) #create fl ch \n",
    "                cfiles = [fnfmt(l, channel.name.lower()) for l in label_files]\n",
    "                files[channel]['path'] += [s+'/'+channel.name.lower()+'/'+f for f in cfiles]\n",
    "                files[channel]['files'] += cfiles #filenames \n",
    "                files[channel]['sets'] += [s] * len(label_files)\n",
    "                for f in cfiles:\n",
    "                    print(f'Adding gaussian noise fluorescence file: {f}')\n",
    "                    shape = [files[channels[0]]['data'][0].shape]\n",
    "                    random = np.random.normal(loc=128, scale=128, size=(shape[0])) #(1024,1024)) what is the stdev of an 8bit image?\n",
    "                    ### need to check if this is really the best way of generating a random image\n",
    "                    random_path = os.path.join(channel_dir, f)\n",
    "                    io.imsave(random_path, random.astype('uint8'))\n",
    "                files[channel]['data'] += [io.imread(os.path.join(pth, s, channel.name.lower(), f)) for f in cfiles]            \n",
    "                    \"\"\"\n",
    "        # now look for weights \n",
    "        w_root = os.path.join(pth, s, 'weights') ### change this back to 'weights' and have func to rename previous weight folder?\n",
    "        #if os.path.exists(w_root):\n",
    "        wfiles = [fnfmt(l, 'weights') for l in label_files]\n",
    "        for weight_file in wfiles:\n",
    "            files[Channels.WEIGHTS]['path'] += [f'{s}/weights/{weight_file}']\n",
    "            files[Channels.WEIGHTS]['files'] += [weight_file]\n",
    "            files[Channels.WEIGHTS]['sets'] += [s]\n",
    "            if os.path.exists(os.path.join(w_root, weight_file)):\n",
    "                files[Channels.WEIGHTS]['data'] += [io.imread(os.path.join(w_root, weight_file)).astype(np.float32)]\n",
    "            else:\n",
    "                print(f'Adding empty weight file: {weight_file}')\n",
    "                mask_shape = files[channels[0]]['data'][0].shape\n",
    "                files[Channels.WEIGHTS]['data'] += [np.zeros(mask_shape, dtype=np.float32)]\n",
    "                \n",
    "    \"\"\"check for fluorescent channels, if not there, add fluorescent folders, then add gaussian noise\"\"\"            \n",
    "\n",
    "    w_root = os.path.join(pth, s, 'weights')\n",
    "                                                         \n",
    "    # now make image stacks \n",
    "    for channel in files.keys():\n",
    "        for i, im in enumerate(files[channel]['data']):\n",
    "            print(channel, files[channel]['path'][i], im.shape, im.dtype)\n",
    "        \n",
    "        files[channel]['data'] = np.stack(files[channel]['data'], axis=0)\n",
    "        \n",
    "    global shape\n",
    "    shape = files[channels[0]]['data'][0].shape\n",
    "\n",
    "    return files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels.MASK set1/labels/0100_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set2/labels/0031_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set3/labels/0000_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set4/labels/0000_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set5/labels/0000_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set6/labels/0009_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set7/labels/0229_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set8/labels/0000_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set9/labels/0020_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set10/labels/0000_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set11/labels/0625_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set12/labels/0033_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set13/labels/0039_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set14/labels/0010_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set15/labels/0045_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set16/labels/0064_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.WEIGHTS set1/weights/0100_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set2/weights/0031_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set3/weights/0000_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set4/weights/0000_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set5/weights/0000_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set6/weights/0009_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set7/weights/0229_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set8/weights/0000_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set9/weights/0020_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set10/weights/0000_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set11/weights/0625_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set12/weights/0033_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set13/weights/0039_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set14/weights/0010_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set15/weights/0045_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set16/weights/0064_weights.tif (1024, 1024) float32\n",
      "Channels.PHASE set1/phase/0100_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set2/phase/0031_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set3/phase/0000_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set4/phase/0000_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set5/phase/0000_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set6/phase/0009_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set7/phase/0229_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set8/phase/0000_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set9/phase/0020_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set10/phase/0000_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set11/phase/0625_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set12/phase/0033_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set13/phase/0039_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set14/phase/0010_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set15/phase/0045_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set16/phase/0064_phase.tif (1024, 1024) uint16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/notebooks/napari/tifffile.py:2170: UserWarning: failed to import _tifffile.decodepackbits\n",
      "  warnings.warn(\"failed to import %s\" % module_function)\n",
      "/home/nathan/analysis/notebooks/napari/tifffile.py:2170: UserWarning: failed to import _tifffile.decodelzw\n",
      "  warnings.warn(\"failed to import %s\" % module_function)\n",
      "/home/nathan/analysis/notebooks/napari/tifffile.py:2170: UserWarning: failed to import _tifffile.unpackints\n",
      "  warnings.warn(\"failed to import %s\" % module_function)\n"
     ]
    }
   ],
   "source": [
    "channels = [Channels[c.upper()] for c in ACQUISITION_CHANNELS]\n",
    "data = load_training_data(DATA_PATH, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(stack):\n",
    "    normed = stack.astype(np.float32)\n",
    "    \n",
    "    for i in range(stack.shape[0]):\n",
    "        # normed[i,...] = (normed[i,...]-np.mean(normed[i,...])) / np.std(normed[i,...])\n",
    "        c = normed[i,...]\n",
    "        p_lo = np.percentile(c,5)\n",
    "        p_hi = np.percentile(c,99)\n",
    "        normed[i,...] = np.clip((c - p_lo) / p_hi, 0., 1.)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_boxes(seg):\n",
    "    lbl, nlbl = ndimage.label(seg)\n",
    "    class_label, _, minxy, maxxy = ndimage.extrema(seg, lbl, index=np.arange(1, nlbl+1))\n",
    "    return class_label, minxy, maxxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = np.zeros(data[channels[0]]['data'].shape, dtype=np.uint8)\n",
    "mask = data[Channels.MASK]['data']\n",
    "if mask.ndim == 3:\n",
    "    seg = mask > 0\n",
    "elif mask.ndim == 4:\n",
    "    seg[mask[:,0,...]>0] = 1\n",
    "    seg[mask[:,1,...]>0] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mask(labels, unique_labels=range(1,len(channels)+1)):\n",
    "    print(unique_labels)\n",
    "    seg = np.zeros((len(unique_labels),)+labels.shape, dtype=np.uint8)\n",
    "    for i,l in enumerate(unique_labels):\n",
    "        seg[i,...] = labels==l\n",
    "    return np.squeeze(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_labels(viewer):\n",
    "    # get the current image \n",
    "    current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "    source_set = data[Channels.MASK]['sets'][current_slice]\n",
    "    source_file = data[Channels.MASK]['files'][current_slice]\n",
    "    source_fn = os.path.join(source_set, 'labels', source_file)\n",
    "\n",
    "    # get the current layer\n",
    "    current_labels = viewer.layers['labels'].data[current_slice,...]\n",
    "    current_mask = convert_to_mask(current_labels)\n",
    "\n",
    "    # write out the modified segmentation mask\n",
    "    new_file = os.path.join(DATA_PATH, source_fn+'.modified.tif')\n",
    "    print(new_file)\n",
    "    io.imsave(new_file, current_mask[0].astype('uint8'))\n",
    "\n",
    "    print(current_slice, current_labels.shape, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_labels(viewer):\n",
    "        # get the current image \n",
    "    current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "    #current_slice = viewer.layers[viewer.active_layer].coordinates[1] # prints the x coord\n",
    "    \n",
    "    source_set = data[Channels.MASK]['sets'][current_slice]\n",
    "    source_file = data[Channels.MASK]['files'][current_slice]\n",
    "    source_fn = os.path.join(source_set, 'labels', source_file)\n",
    "\n",
    "    # get the current layer\n",
    "    current_labels = viewer.layers['labels'].data[current_slice,...]\n",
    "    current_mask = convert_to_mask(current_labels)\n",
    "    \n",
    "    # for over all stack\n",
    "    #for i in range(len(data[Channels.MASK]['files'])):\n",
    "    for i in range(viewer.layers['labels'].data.shape[0]):\n",
    "        current_slice = i\n",
    "        \n",
    "        source_set = data[Channels.MASK]['sets'][current_slice]\n",
    "        source_file = data[Channels.MASK]['files'][current_slice]\n",
    "        source_fn = os.path.join(source_set, 'labels', source_file)\n",
    "        \n",
    "        current_labels = viewer.layers['labels'].data[current_slice,...]\n",
    "        current_mask = convert_to_mask(current_labels)\n",
    "        \n",
    "        new_file = os.path.join(DATA_PATH, source_fn+'.modified.tif')\n",
    "        print(new_file)\n",
    "        io.imsave(new_file, current_mask[0].astype('uint8'))\n",
    "\n",
    "        print(current_slice, current_labels.shape, new_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weightmaps = np.zeros((seg.shape), dtype=np.float32)\n",
    "\n",
    "def calculate_weightmaps(viewer, w0=WEIGHT_AMPLITUDE, current_slice=0):\n",
    "    # get the current layer and make it binary\n",
    "    mask = viewer.layers['labels'].data[current_slice,...].astype(np.bool)\n",
    "    \n",
    "    # label the image \n",
    "    labelled, n_labels = ndimage.label(mask)\n",
    "    #print(n_labels)\n",
    "    weight_mask = np.zeros(mask.shape, dtype=np.float32)\n",
    "    for i in range(1,n_labels+1):\n",
    "        cell = labelled == i\n",
    "        not_cell = np.logical_xor(cell, mask) #np.logical_and(labelled != i, labelled > 0)\n",
    "        mask_diff = gaussian_filter(cell.astype(np.float32), sigma=5) * gaussian_filter(not_cell.astype(np.float32), sigma=5)\n",
    "        weight_mask += mask_diff\n",
    "\n",
    "    wmap = w0*weight_mask #* wmap\n",
    "    \n",
    "    # normalize it\n",
    "    wmap += 1.   \n",
    "    wmap[mask] = 1.\n",
    "      \n",
    "    viewer.layers['weightmaps'].data[current_slice,...] = wmap.astype(np.float32)\n",
    "    viewer.layers['weightmaps'].contrast_limits = (np.min(wmap), np.max(wmap))\n",
    "    viewer.layers['weightmaps'].visible = True\n",
    "    \n",
    "    return wmap\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary weighting = weightmap * weightmask\n",
    "# purpose is to create a secondary weightmap that can be used to tell the network to focus/ignore on user-selected ROIs\n",
    "\n",
    "def calculate_custom_weightmap(viewer, current_slice=0):\n",
    "    \n",
    "    w_mask = viewer.layers['weightmask'].data[current_slice,...].astype(np.bool)\n",
    "    w_map =  viewer.layers['weightmaps'].data[current_slice,...]   \n",
    "    cust_wmap = w_map*w_mask\n",
    "        \n",
    "    #viewer.add_image(cust_wmap, name='custom weightmap', colormap='plasma', visible=True) # by having this here we generate a new custwm image each time one is generated instead of adding to stack\n",
    "    \n",
    "    #cust_wmap += 1.   \n",
    "    #cust_wmap[w_mask] = 1. #is this necessary? not at the moment\n",
    "    \n",
    "    viewer.layers['custom weightmap'].data[current_slice,...] = cust_wmap.astype(np.float32) # need this line to \n",
    "    viewer.layers['custom weightmap'].contrast_limits = (np.min(cust_wmap), np.max(cust_wmap))\n",
    "    viewer.layers['custom weightmap'].visible = True\n",
    "    \n",
    "    return cust_wmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow_shrink_label(viewer, grow=True, n_iter=1): #by editing the number of iterations i can edit the size of growshrink\n",
    "    # get the current image \n",
    "    current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "    current_labels = viewer.layers['labels'].data[current_slice,...] #label as in image\n",
    "            \n",
    "    cursor_coords = [int(p) for p in viewer.layers[viewer.active_layer].position]\n",
    "    labelled, _ = ndimage.label(current_labels.astype(np.bool)) #each obj in label image is labelled\n",
    "    real_label = current_labels[cursor_coords[0], cursor_coords[1]] #xy cursor coords in current label image\n",
    "    \n",
    "    if real_label < 1: return\n",
    "    \n",
    "    mask = labelled == labelled[cursor_coords[0], cursor_coords[1]] #assigning mask as labelled image with only xy of specific cell\n",
    "    if grow:\n",
    "        mask = ndimage.morphology.binary_dilation(mask, iterations=n_iter)   \n",
    "    else:\n",
    "        current_labels[mask] = 0\n",
    "        mask = ndimage.morphology.binary_erosion(mask, iterations=n_iter)\n",
    "    current_labels[mask] = real_label\n",
    "    viewer.layers['labels'].data[current_slice,...] = current_labels\n",
    "    viewer.layers['labels']._set_view_slice()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cells(viewer):\n",
    "    current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "    mask = viewer.layers['labels'].data[current_slice,...].astype(np.bool) \n",
    "    labelled, n_labels = ndimage.label(mask)\n",
    "       \n",
    "    #print('number of labels/cells in displayed mask is:', n_labels)\n",
    "    stat_file = os.path.join(DATA_PATH, 'stats.csv')\n",
    "    \n",
    "    i=0\n",
    "    df=pd.DataFrame(data=[0], index=[i], columns=['number of cells'])\n",
    "    \n",
    "    for i in range(viewer.layers['labels'].data.shape[0]):\n",
    "        current_slice = i\n",
    "        mask = viewer.layers['labels'].data[current_slice,...].astype(np.bool) \n",
    "        labelled, n_labels = ndimage.label(mask)\n",
    "            \n",
    "        df.loc[i] = n_labels\n",
    "        df.to_csv(stat_file, index=False)\n",
    "    print(df)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_holes(viewer):\n",
    "    current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "    current_labels = viewer.layers['labels'].data[current_slice,...] #label as in image\n",
    "            \n",
    "    cursor_coords = [int(p) for p in viewer.layers[viewer.active_layer].position]\n",
    "    labelled, _ = ndimage.label(current_labels.astype(np.bool)) #each obj in label image is labelled\n",
    "    real_label = current_labels[cursor_coords[0], cursor_coords[1]] #xy cursor coords in current label image\n",
    "    \n",
    "    if real_label < 1: return\n",
    "    \n",
    "    mask = labelled == labelled[cursor_coords[0], cursor_coords[1]] #assigning mask as labelled image with only xy of specific cell\n",
    "    mask = ndimage.morphology.binary_fill_holes(mask) \n",
    "    current_labels[mask] = real_label\n",
    "    viewer.layers['labels'].data[current_slice,...] = current_labels\n",
    "    viewer.layers['labels']._set_view_slice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_cell_mask(viewer):  #by editing the number of iterations i can edit the size of growshrink\n",
    "    # get the current image \n",
    "    current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "    current_labels = viewer.layers['labels'].data[current_slice,...] #label as in image\n",
    "    \n",
    "        \n",
    "    cursor_coords = [int(p) for p in viewer.layers[viewer.active_layer].position]\n",
    "    labelled, _ = ndimage.label(current_labels.astype(np.bool)) #each obj in label image is labelled\n",
    "    real_label = current_labels[cursor_coords[0], cursor_coords[1]] #xy cursor coords in current label image\n",
    "    \n",
    "    if real_label < 1: return\n",
    "    \n",
    "    mask = labelled == labelled[cursor_coords[0], cursor_coords[1]] #assigning mask as labelled image with only xy of specific cell\n",
    "    #print(mask) # we want this image mask here saved as current labels\n",
    "    \n",
    "    current_labels = mask    \n",
    "    #current_labels[mask] = real_label\n",
    "    viewer.layers['labels'].data[current_slice,...] = current_labels\n",
    "    viewer.layers['labels']._set_view_slice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fluorescent_noise(viewer):\n",
    "    pth = DATA_PATH\n",
    "    for s in sets:\n",
    "        #add input for gfp and rfp\n",
    "        channels = [Channels[c.upper()] for c in INCOMPLETE_CHANNELS]\n",
    "        incomplete_files = {k:{'files':[], 'data':[], 'sets':[], 'path':[]} for k in channels} #need to add something like this to include Channels.GFP etc in files[channels]        \n",
    "        files.update(incomplete_files) #merging two dicts to create complete file dict\n",
    "        for channel in channels:\n",
    "            \n",
    "               #if cfiles channel.name.lower dir doesnt contain gfp or rfp then add option to create noise data,\n",
    "                channel_dir = os.path.join(pth, s, channel.name.lower())            \n",
    "                if os.path.exists(channel_dir): #if fluor/phase channels exist, continue as norm\n",
    "                    cfiles = [fnfmt(l, channel.name.lower()) for l in label_files]                  \n",
    "                    files[channel]['path'] += [s+'/'+channel.name.lower()+'/'+f for f in cfiles]\n",
    "                    files[channel]['files'] += cfiles #filenames\n",
    "                    files[channel]['data'] += [io.imread(os.path.join(pth, s, channel.name.lower(), f)) for f in cfiles] #actualdata\n",
    "                    files[channel]['sets'] += [s] * len(label_files)\n",
    "\n",
    "                else: #if fluor ch missing then create one and fill it with noise - should add this to separate func later\n",
    "                    os.mkdir(channel_dir) #create fl ch \n",
    "                    cfiles = [fnfmt(l, channel.name.lower()) for l in label_files]\n",
    "                    files[channel]['path'] += [s+'/'+channel.name.lower()+'/'+f for f in cfiles]\n",
    "                    files[channel]['files'] += cfiles #filenames \n",
    "                    files[channel]['sets'] += [s] * len(label_files)\n",
    "                    for f in cfiles:\n",
    "                        print(f'Adding gaussian noise fluorescence file: {f}')             \n",
    "                        #shape = [files[channels[0]]['data'][0].shape]\n",
    "                        random = np.random.normal(loc=128, scale=128, size=shape) #(1024,1024)) what is the stdev of an 8bit image?\n",
    "                        ### need to check if this is really the best way of generating a random image\n",
    "                        random_path = os.path.join(channel_dir, f)\n",
    "                        io.imsave(random_path, random.astype('uint8'))\n",
    "                    files[channel]['data'] += [io.imread(os.path.join(pth, s, channel.name.lower(), f)) for f in cfiles]\n",
    "\n",
    "    if Channels.GFP in data:\n",
    "        #gfp = normalize_images(data[Channels.GFP]['data'])\n",
    "        gfp = data[Channels.GFP]['data']\n",
    "        print(gfp)\n",
    "        viewer.add_image(gfp, name='GFP', colormap='green', contrast_limits=(0.,1.))\n",
    "        viewer.layers['RFP'].blending = 'additive'\n",
    "        \n",
    "    if Channels.RFP in data:\n",
    "        #rfp = normalize_images(data[Channels.RFP]['data'])\n",
    "        viewer.add_image(rfp, name='RFP', colormap='magenta', contrast_limits=(0.,1.))\n",
    "        viewer.layers['RFP'].blending = 'additive'\n",
    "        \n",
    "    if Channels.IRFP in data:\n",
    "        #irfp = normalize_images(data[Channels.RFP]['data'])\n",
    "        viewer.add_image(irfp, name='iRFP', colormap='inferno', contrast_limits=(0.,1.)) #maybe change colormap\n",
    "        viewer.layers['IRFP'].blending = 'additive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating simulated fluorescence channels with gaussian noise\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "Adding gaussian noise fluorescence file: 0064_gfp.tif\n",
      "[array([[193, 170,  54, ..., 125,  88,  45],\n",
      "       [235, 117, 203, ...,   3, 185, 247],\n",
      "       [156,  93, 113, ...,  76, 248,  85],\n",
      "       ...,\n",
      "       [215,   6,   8, ..., 151, 143, 130],\n",
      "       [ 56, 142,  43, ..., 124, 209,  44],\n",
      "       [  2, 180,  40, ..., 163,  94, 133]], dtype=uint8)]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/napari/lib/python3.7/site-packages/vispy/app/backends/_qt.py\u001b[0m in \u001b[0;36mkeyPressEvent\u001b[0;34m(self, ev)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeyPressEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keyEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vispy_canvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_press\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeyReleaseEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/napari/lib/python3.7/site-packages/vispy/app/backends/_qt.py\u001b[0m in \u001b[0;36m_keyEvent\u001b[0;34m(self, func, ev)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodifiers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_modifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/napari/lib/python3.7/site-packages/vispy/util/event.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/napari/lib/python3.7/site-packages/vispy/util/event.py\u001b[0m in \u001b[0;36m_invoke_callback\u001b[0;34m(self, cb, event)\u001b[0m\n\u001b[1;32m    473\u001b[0m             _handle_exception(self.ignore_callback_errors,\n\u001b[1;32m    474\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_callback_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                               self, cb_event=(cb, event))\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/napari/lib/python3.7/site-packages/vispy/util/event.py\u001b[0m in \u001b[0;36m_invoke_callback\u001b[0;34m(self, cb, event)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_invoke_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             _handle_exception(self.ignore_callback_errors,\n",
      "\u001b[0;32m~/anaconda3/envs/napari/lib/python3.7/site-packages/napari/_qt/qt_viewer.py\u001b[0m in \u001b[0;36mon_key_press\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeymap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-725a42f599f3>\u001b[0m in \u001b[0;36mk_fluorescent_noise\u001b[0;34m(viewer)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mk_fluorescent_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating simulated fluorescence channels with gaussian noise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mfluorescent_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#double command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-b70a1df9518b>\u001b[0m in \u001b[0;36mfluorescent_noise\u001b[0;34m(viewer)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mgfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChannels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFP\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GFP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolormap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'green'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrast_limits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RFP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'additive'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/napari/lib/python3.7/site-packages/napari/components/add_layers_mixin.py\u001b[0m in \u001b[0;36madd_image\u001b[0;34m(self, data, channel_axis, rgb, is_pyramid, colormap, contrast_limits, gamma, interpolation, rendering, iso_threshold, attenuation, name, metadata, scale, translate, opacity, blending, visible, path)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mopacity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopacity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mblending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblending\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvisible\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             )\n\u001b[1;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/napari/lib/python3.7/site-packages/napari/layers/image/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, rgb, is_pyramid, colormap, contrast_limits, gamma, interpolation, rendering, iso_threshold, attenuation, name, metadata, scale, translate, opacity, blending, visible)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         ndim, rgb, is_pyramid, data_pyramid = get_pyramid_and_rgb(\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpyramid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_pyramid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrgb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         )\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/napari/lib/python3.7/site-packages/napari/layers/image/image_utils.py\u001b[0m in \u001b[0;36mget_pyramid_and_rgb\u001b[0;34m(data, pyramid, rgb)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0minit_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0minit_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;31m# Determine if rgb, and determine dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# start napari\n",
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer()\n",
    "    \n",
    "    if Channels.GFP in data:\n",
    "        gfp = normalize_images(data[Channels.GFP]['data'])\n",
    "        viewer.add_image(gfp, name='GFP', colormap='green', contrast_limits=(0.,1.))\n",
    "        \n",
    "    if Channels.RFP in data:\n",
    "        rfp = normalize_images(data[Channels.RFP]['data'])\n",
    "        viewer.add_image(rfp, name='RFP', colormap='magenta', contrast_limits=(0.,1.))\n",
    "        viewer.layers['RFP'].blending = 'additive'\n",
    "        \n",
    "    if Channels.PHASE in data:\n",
    "        phase = normalize_images(data[Channels.PHASE]['data'])\n",
    "        viewer.add_image(phase, name='Phase', colormap='gray')\n",
    "    \n",
    "    if Channels.WEIGHTS in data:\n",
    "        weightmaps = data[Channels.WEIGHTS]['data']\n",
    "        viewer.add_image(weightmaps, name='weightmaps', colormap='plasma', visible=False)\n",
    "        \n",
    "    if Channels.WEIGHTS in data:\n",
    "        cust_wmap = data[Channels.WEIGHTS]['data']\n",
    "        viewer.add_image(cust_wmap, name='custom weightmap', colormap='plasma', visible=False)\n",
    "    \n",
    "    viewer.add_labels(seg, name='labels')\n",
    "    viewer.layers['labels'].opacity = 0.4\n",
    "    viewer.layers['weightmaps'].blending = 'additive'\n",
    "    \n",
    "    weight_mask = np.ones(data[Channels.WEIGHTS]['data'].shape, dtype=np.uint8)\n",
    "    #cust_wmap = np.ones(data[Channels.WEIGHTS]['data'].shape, dtype=np.uint8)\n",
    "    viewer.add_labels(weight_mask, name='weightmask', visible=False)\n",
    "    #viewer.add_image(cust_wmap, name='custom weightmap', colormap='plasma', visible=False)\n",
    "\n",
    "    @viewer.bind_key('g')\n",
    "    def k_fluorescent_noise(viewer):\n",
    "        print(\"Creating simulated fluorescence channels with gaussian noise\")\n",
    "        fluorescent_noise(viewer) \n",
    "            \n",
    "    @viewer.bind_key('/') #double command\n",
    "    def k_save_labels(viewer):\n",
    "        save_labels(viewer)  #need to change the (viewer) bit to save all images   \n",
    "        \n",
    "    @viewer.bind_key('s')\n",
    "    def k_save_all_labels(viewer):\n",
    "        save_all_labels(viewer)\n",
    "        \n",
    "    @viewer.bind_key('n')\n",
    "    def k_count_cells(viewer):\n",
    "        count_cells(viewer)\n",
    "        \n",
    "    @viewer.bind_key('w')\n",
    "    def k_calculate_weightmaps(viewer):\n",
    "        current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "        calculate_weightmaps(viewer, current_slice=current_slice)\n",
    "        ## calculate cust_ here?\n",
    "        \n",
    "    @viewer.bind_key('q')\n",
    "    def k_calculate_custom_weightmap(viewer):\n",
    "        current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "        calculate_custom_weightmap(viewer, current_slice=current_slice)\n",
    "        \n",
    "    @viewer.bind_key('<')\n",
    "    def k_shrink_label(viewer):\n",
    "        print('shrink label')\n",
    "        grow_shrink_label(viewer, grow=False)\n",
    "    \n",
    "    @viewer.bind_key('>') \n",
    "    def k_grow_label(viewer):\n",
    "        print('grow label')\n",
    "        grow_shrink_label(viewer, grow=True)\n",
    "        \n",
    "    @viewer.bind_key('c') #clear\n",
    "    def k_single_cell(viewer):\n",
    "        print('select cell')\n",
    "        single_cell_mask(viewer)\n",
    "        \n",
    "    @viewer.bind_key('h') #fill holes in cell masks\n",
    "    def k_fill_holes(viewer):\n",
    "        print('filling holes in cell mask')\n",
    "        fill_holes(viewer) \n",
    "    \n",
    "    @viewer.bind_key('o')\n",
    "    def k_output(viewer):\n",
    "        print('Output all with metadata')\n",
    "                \n",
    "        for i in range(viewer.layers['weightmaps'].data.shape[0]):\n",
    "            \n",
    "            if np.sum(viewer.layers['weightmaps'].data[i,...]) == 0: # get rid of this condition to calculate weightmaps afresh regardless?\n",
    "                print(f'Weightmap {i} is empty. Calculating...')\n",
    "                wmap = calculate_weightmaps(viewer, current_slice=i)\n",
    "                weight_folder = os.path.join(DATA_PATH, data[Channels.WEIGHTS]['sets'][i], 'weights')\n",
    "                weight_fn = data[Channels.WEIGHTS]['files'][i]\n",
    "                print(weight_folder, weight_fn)\n",
    "                make_folder(weight_folder)\n",
    "                io.imsave(os.path.join(weight_folder, weight_fn), wmap.astype(np.float32))\n",
    "          \n",
    "                #write out cust_weight_map too\n",
    "                \n",
    "                cust_wmap = calculate_custom_weightmap(viewer, current_slice=i)\n",
    "                cust_weight_folder = os.path.join(DATA_PATH, data[Channels.WEIGHTS]['sets'][i], 'custom_weights')       \n",
    "                #os.path.join((data[Channels.WEIGHTS]['files'][i][:+]),'.custom.tif')\n",
    "                cust_weight_fn = data[Channels.WEIGHTS]['files'][i] ##add custom to this fn!!!!!!!!!!!! or do i want to keep fn as before for forward compatability?\n",
    "                print(cust_weight_folder, cust_weight_fn)\n",
    "                make_folder(cust_weight_folder)\n",
    "                io.imsave(os.path.join(cust_weight_folder, cust_weight_fn), cust_wmap.astype(np.float32))\n",
    "                \n",
    "                ## adding save out of the weight masks\n",
    "                w_mask = viewer.layers['weightmask'].data[i,...].astype(np.bool)                \n",
    "                weight_mask_folder = os.path.join(DATA_PATH, data[Channels.WEIGHTS]['sets'][i], 'weight_masks')\n",
    "                weight_mask_fn = data[Channels.MASK]['files'][i] ##add weight to fn\n",
    "                print(weight_mask_folder, weight_mask_fn)\n",
    "                make_folder(weight_mask_folder)\n",
    "                io.imsave(os.path.join(weight_mask_folder, weight_mask_fn), w_mask.astype(np.float32))\n",
    "                \n",
    "                \n",
    "        # write out a JSON file with the data\n",
    "        jfn = os.path.join(DATA_PATH, 'training_metadata.json')\n",
    "        jdata = {}\n",
    "        for channel in data.keys():\n",
    "            jdata[channel.name.lower()] = data[channel]['path']\n",
    "            \n",
    "        with open(jfn, 'w') as json_file:\n",
    "            json.dump(jdata, json_file, indent=2, separators=(',', ': '))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert segmentation output labels to multichannel stacks\n",
    "\n",
    "# p = '/Users/arl/Dropbox/Data/TrainingData/set12'\n",
    "# files = [f for f in os.listdir(os.path.join(p,'labels')) if f.endswith('.tif')]\n",
    "# for f in files:\n",
    "#     mask = io.imread(os.path.join(p, 'labels', f))\n",
    "#     print(mask.shape)\n",
    "#     gfp = mask==1\n",
    "#     rfp = mask==2\n",
    "#     new_mask = np.stack([gfp, rfp], axis=0)\n",
    "#     io.imsave(os.path.join(p,f), new_mask.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:napari]",
   "language": "python",
   "name": "conda-env-napari-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
