{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAPARI visualization of UNet Training Data\n",
    "\n",
    "You can use this notebook to view, modified and save out training data for UNet models\n",
    "\n",
    "Labels:\n",
    "+ 0 - background \n",
    "+ 1 - GFP/Phase \n",
    "+ 2 - RFP\n",
    "\n",
    "\n",
    "Extra key bindings:\n",
    "+ 'w' - calculate weightmap\n",
    "+ 'q' - calculate custom annotated weightmap (weightmask * weightmap)\n",
    "+ '/' - save label current displayed\n",
    "+ 's' - save all labels\n",
    "+ 'o' - output all weightmaps and metadata for tfrecord creation\n",
    "+ '\\>' - grow the label under the mouse cursor\n",
    "+ '\\<' - shrink the label under the mouse cursor\n",
    "+ 'h' - fill holes in cell mask under the mouse cursor\n",
    "+ 'n' - count cells (will be updated to collect more stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "```\n",
    "Authors:\n",
    "- Alan R. Lowe (a.lowe@ucl.ac.uk)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Set up the data path, channel(s) used, weight amplitude and the number of images to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = '/home/nathan/analysis/training/training_data'\n",
    "DATA_PATH = '/home/nathan/analysis/fucci/working_dir/all/full_stack'\n",
    "\n",
    "WEIGHT_AMPLITUDE = 3.\n",
    "ACQUISION_CHANNELS = ['PHASE']\n",
    "NUMBER_OF_IMAGES_TO_LOAD = 0 #'ALL' #from index 0, loads in numerical order, if all images desired then enter 'ALL'\n",
    "INDEX_OF_IMAGES = [500, 503] #enter [min, max] and ensure NUMBER_OF_IMAGES_TO_LOAD = 0\n",
    "#INDEX_OF_IMAGES = [minimum:maximum]\n",
    "#ACQUISION_CHANNELS = ['GFP', 'RFP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import enum\n",
    "import json\n",
    "import csv\n",
    "import napari\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from itertools import islice\n",
    "\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@enum.unique\n",
    "class Channels(enum.Enum):\n",
    "    BRIGHTFIELD = 0 \n",
    "    GFP = 1\n",
    "    RFP = 2\n",
    "    IRFP = 3\n",
    "    PHASE = 4\n",
    "    WEIGHTS = 98\n",
    "    MASK = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_modified_filename(filename):\n",
    "    if filename.endswith('.modified.tif'):\n",
    "        stripped_fn = filename[:-len('.modified.tif')]\n",
    "        return stripped_fn\n",
    "    return filename\n",
    "\n",
    "def make_folder(foldername):\n",
    "    if os.path.exists(foldername):\n",
    "        return\n",
    "    os.mkdir(foldername)\n",
    "    \n",
    "def file_root(filename):\n",
    "    FILENAME_PATTERN = r'([a-zA-Z0-9]+)_([a-zA-Z0-9]+)_*.tif'\n",
    "    grps = re.search(FILENAME_PATTERN, filename)\n",
    "    return grps\n",
    "\n",
    "def load_training_data(pth, channels=[Channels.GFP, Channels.RFP]):\n",
    "    \"\"\" load training data for visualisation with napari \"\"\"\n",
    "          \n",
    "    # find the sets and sort them\n",
    "    sets = [f for f in os.listdir(pth) if os.path.isdir(os.path.join(pth, f))]\n",
    "    sets.sort(key = lambda s: int(s[3:]))\n",
    "    \n",
    "    def set_filename_format(filename):\n",
    "        grps = file_root(filename)\n",
    "        if grps.group(1) in [c.name.lower() for c in all_channels]:\n",
    "            FILENAME_FORMAT = 2\n",
    "        else:\n",
    "            FILENAME_FORMAT = 1\n",
    "            \n",
    "        def filename_formatter(filename, channel):\n",
    "            # assert(channel in [c.name.lower() for c in all_channels])\n",
    "            grps = file_root(filename)\n",
    "\n",
    "            return f'{grps.group(FILENAME_FORMAT)}_{channel}.tif'\n",
    "            # return '{}_{}.tif'.format(*[channel, grps.group(FILENAME_FORMAT)])\n",
    "        \n",
    "        return filename_formatter\n",
    "    \n",
    "    all_channels = [Channels.MASK, Channels.WEIGHTS]+channels\n",
    "    files = {k:{'files':[], 'data':[], 'sets':[], 'path':[]} for k in all_channels}\n",
    "    all_channels.remove(Channels.WEIGHTS)\n",
    "    \n",
    "    for s in sets:\n",
    "\n",
    "        # root_folders\n",
    "        l_root = os.path.join(pth, s, 'labels')\n",
    "        \n",
    "        # check that this folder exists \n",
    "        if not os.path.exists(l_root):\n",
    "            raise IOError(f'{l_root} does not exist. Do you need to rename label -> labels?')\n",
    "\n",
    "        # get the training label files\n",
    "        label_files = [f for f in os.listdir(l_root) if f.endswith('.tif')]\n",
    "        #print(label_files)\n",
    "        \n",
    "        # sort to remove unmodified files and replace with the modified files\n",
    "        unmodified_files, modified_files = [], []\n",
    "        \n",
    "        #for index, item in enumerate(islice(items, limit)):\n",
    "        for i, f in enumerate(label_files): #introducing islice here allows you to choose size of dataset! but only in a random order\n",
    "            if f.endswith('.modified.tif'):\n",
    "                modified_files.append(strip_modified_filename(f))\n",
    "            else:\n",
    "                unmodified_files.append(f)\n",
    "                \n",
    "        unmodified_files = list(set(unmodified_files).difference(set(modified_files)))\n",
    "        label_files_full = unmodified_files + [f+'.modified.tif' for f in modified_files]\n",
    "                \n",
    "        label_files_full.sort(key = lambda f: int(f[0:4])) #sorts files numerically\n",
    "        \n",
    "        N = NUMBER_OF_IMAGES_TO_LOAD\n",
    "        n = INDEX_OF_IMAGES[0]\n",
    "        m = INDEX_OF_IMAGES[1]\n",
    "        \n",
    "        if N == 'ALL':\n",
    "            label_files = label_files_full\n",
    "        elif N > 0:\n",
    "            label_files = label_files_full[:N] #cuts list of files to N images\n",
    "        else:\n",
    "            label_files = label_files_full[n:m] #cuts list of files to n->m images\n",
    "               \n",
    "        ## MAKE THIS ELIF TIDIER SO ONLY ONE INPUT IS REQUIRED ##        \n",
    "                \n",
    "        \"\"\"if isinstance(N, int):\n",
    "            label_files = label_files_full[:N] #cuts list of files to N images             \n",
    "        else: \n",
    "            #label_files = label_files_full[INDEX_OF_IMAGES[0],INDEX_OF_IMAGES[1]] #cuts list of files to N images\n",
    "        #print(label_files)\"\"\"\n",
    "        \n",
    "        fnfmt = set_filename_format(label_files[0])\n",
    "                \n",
    "        files[Channels.MASK]['path'] += [s+'/labels/'+f for f in label_files]\n",
    "        files[Channels.MASK]['files'] += [strip_modified_filename(f) for f in label_files]\n",
    "        files[Channels.MASK]['data'] += [io.imread(os.path.join(l_root, f)) for f in label_files]\n",
    "        files[Channels.MASK]['sets'] += [s] * len(label_files)\n",
    "        \n",
    "        for channel in channels:\n",
    "            cfiles = [fnfmt(l, channel.name.lower()) for l in label_files]\n",
    "            files[channel]['path'] += [s+'/'+channel.name.lower()+'/'+f for f in cfiles]\n",
    "            files[channel]['files'] += cfiles\n",
    "            files[channel]['data'] += [io.imread(os.path.join(pth, s, channel.name.lower(), f)) for f in cfiles]\n",
    "            files[channel]['sets'] += [s] * len(label_files)\n",
    "            \n",
    "        # now look for weights \n",
    "        w_root = os.path.join(pth, s, 'weights') ### change this back to 'weights' and have func to rename previous weight folder?\n",
    "#         if os.path.exists(w_root):\n",
    "        wfiles = [fnfmt(l, 'weights') for l in label_files]\n",
    "        for weight_file in wfiles:\n",
    "            files[Channels.WEIGHTS]['path'] += [f'{s}/weights/{weight_file}']\n",
    "            files[Channels.WEIGHTS]['files'] += [weight_file]\n",
    "            files[Channels.WEIGHTS]['sets'] += [s]\n",
    "            if os.path.exists(os.path.join(w_root, weight_file)):\n",
    "                files[Channels.WEIGHTS]['data'] += [io.imread(os.path.join(w_root, weight_file)).astype(np.float32)]\n",
    "            else:\n",
    "                print(f'Adding empty weight file: {weight_file}')\n",
    "                mask_shape = files[channels[0]]['data'][0].shape\n",
    "                files[Channels.WEIGHTS]['data'] += [np.zeros(mask_shape, dtype=np.float32)]\n",
    "                                                         \n",
    "    # now make image stacks \n",
    "    for channel in files.keys():\n",
    "        for i, im in enumerate(files[channel]['data']):\n",
    "            print(channel, files[channel]['path'][i], im.shape, im.dtype)\n",
    "        \n",
    "        files[channel]['data'] = np.stack(files[channel]['data'], axis=0)\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding empty weight file: 0500_weights.tif\n",
      "Adding empty weight file: 0501_weights.tif\n",
      "Adding empty weight file: 0502_weights.tif\n",
      "Channels.MASK set1/labels/0500_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set1/labels/0501_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.MASK set1/labels/0502_mask.tif.modified.tif (1024, 1024) uint8\n",
      "Channels.WEIGHTS set1/weights/0500_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set1/weights/0501_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set1/weights/0502_weights.tif (1024, 1024) float32\n",
      "Channels.PHASE set1/phase/0500_phase.tif (1024, 1024) uint16\n",
      "Channels.PHASE set1/phase/0501_phase.tif (1024, 1024) uint16\n",
      "Channels.PHASE set1/phase/0502_phase.tif (1024, 1024) uint16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/notebooks/napari/tifffile.py:2170: UserWarning: failed to import _tifffile.decodepackbits\n",
      "  warnings.warn(\"failed to import %s\" % module_function)\n",
      "/home/nathan/analysis/notebooks/napari/tifffile.py:2170: UserWarning: failed to import _tifffile.decodelzw\n",
      "  warnings.warn(\"failed to import %s\" % module_function)\n",
      "/home/nathan/analysis/notebooks/napari/tifffile.py:2170: UserWarning: failed to import _tifffile.unpackints\n",
      "  warnings.warn(\"failed to import %s\" % module_function)\n"
     ]
    }
   ],
   "source": [
    "channels = [Channels[c.upper()] for c in ACQUISION_CHANNELS]\n",
    "data = load_training_data(DATA_PATH, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(stack):\n",
    "    normed = stack.astype(np.float32)\n",
    "    \n",
    "    for i in range(stack.shape[0]):\n",
    "        # normed[i,...] = (normed[i,...]-np.mean(normed[i,...])) / np.std(normed[i,...])\n",
    "        c = normed[i,...]\n",
    "        p_lo = np.percentile(c,5)\n",
    "        p_hi = np.percentile(c,99)\n",
    "        normed[i,...] = np.clip((c - p_lo) / p_hi, 0., 1.)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_boxes(seg):\n",
    "    lbl, nlbl = ndimage.label(seg)\n",
    "    class_label, _, minxy, maxxy = ndimage.extrema(seg, lbl, index=np.arange(1, nlbl+1))\n",
    "    return class_label, minxy, maxxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = np.zeros(data[channels[0]]['data'].shape, dtype=np.uint8)\n",
    "mask = data[Channels.MASK]['data']\n",
    "if mask.ndim == 3:\n",
    "    seg = mask > 0\n",
    "elif mask.ndim == 4:\n",
    "    seg[mask[:,0,...]>0] = 1\n",
    "    seg[mask[:,1,...]>0] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mask(labels, unique_labels=range(1,len(channels)+1)):\n",
    "    print(unique_labels)\n",
    "    seg = np.zeros((len(unique_labels),)+labels.shape, dtype=np.uint8)\n",
    "    for i,l in enumerate(unique_labels):\n",
    "        seg[i,...] = labels==l\n",
    "    return np.squeeze(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_labels(viewer):\n",
    "    # get the current image \n",
    "    current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "    source_set = data[Channels.MASK]['sets'][current_slice]\n",
    "    source_file = data[Channels.MASK]['files'][current_slice]\n",
    "    source_fn = os.path.join(source_set, 'labels', source_file)\n",
    "\n",
    "    # get the current layer\n",
    "    current_labels = viewer.layers['labels'].data[current_slice,...]\n",
    "    current_mask = convert_to_mask(current_labels)\n",
    "\n",
    "    # write out the modified segmentation mask\n",
    "    new_file = os.path.join(DATA_PATH, source_fn+'.modified.tif')\n",
    "    print(new_file)\n",
    "    io.imsave(new_file, current_mask[0].astype('uint8'))\n",
    "\n",
    "    print(current_slice, current_labels.shape, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_labels(viewer):\n",
    "        # get the current image \n",
    "    current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "    #current_slice = viewer.layers[viewer.active_layer].coordinates[1] # prints the x coord\n",
    "    \n",
    "    source_set = data[Channels.MASK]['sets'][current_slice]\n",
    "    source_file = data[Channels.MASK]['files'][current_slice]\n",
    "    source_fn = os.path.join(source_set, 'labels', source_file)\n",
    "\n",
    "    # get the current layer\n",
    "    current_labels = viewer.layers['labels'].data[current_slice,...]\n",
    "    current_mask = convert_to_mask(current_labels)\n",
    "    \n",
    "    # for over all stack\n",
    "    #for i in range(len(data[Channels.MASK]['files'])):\n",
    "    for i in range(viewer.layers['labels'].data.shape[0]):\n",
    "        current_slice = i\n",
    "        \n",
    "        source_set = data[Channels.MASK]['sets'][current_slice]\n",
    "        source_file = data[Channels.MASK]['files'][current_slice]\n",
    "        source_fn = os.path.join(source_set, 'labels', source_file)\n",
    "        \n",
    "        current_labels = viewer.layers['labels'].data[current_slice,...]\n",
    "        current_mask = convert_to_mask(current_labels)\n",
    "        \n",
    "        new_file = os.path.join(DATA_PATH, source_fn+'.modified.tif')\n",
    "        print(new_file)\n",
    "        io.imsave(new_file, current_mask[0].astype('uint8'))\n",
    "\n",
    "        print(current_slice, current_labels.shape, new_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weightmaps = np.zeros((seg.shape), dtype=np.float32)\n",
    "\n",
    "def calculate_weightmaps(viewer, w0=WEIGHT_AMPLITUDE, current_slice=0):\n",
    "    # get the current layer and make it binary\n",
    "    mask = viewer.layers['labels'].data[current_slice,...].astype(np.bool)\n",
    "    \n",
    "    # label the image \n",
    "    labelled, n_labels = ndimage.label(mask)\n",
    "    #print(n_labels)\n",
    "    weight_mask = np.zeros(mask.shape, dtype=np.float32)\n",
    "    for i in range(1,n_labels+1):\n",
    "        cell = labelled == i\n",
    "        not_cell = np.logical_xor(cell, mask) #np.logical_and(labelled != i, labelled > 0)\n",
    "        mask_diff = gaussian_filter(cell.astype(np.float32), sigma=5) * gaussian_filter(not_cell.astype(np.float32), sigma=5)\n",
    "        weight_mask += mask_diff\n",
    "\n",
    "    wmap = w0*weight_mask #* wmap\n",
    "    \n",
    "    # normalize it\n",
    "    wmap += 1.   \n",
    "    wmap[mask] = 1.\n",
    "      \n",
    "    viewer.layers['weightmaps'].data[current_slice,...] = wmap.astype(np.float32)\n",
    "    viewer.layers['weightmaps'].contrast_limits = (np.min(wmap), np.max(wmap))\n",
    "    viewer.layers['weightmaps'].visible = True\n",
    "    \n",
    "    return wmap\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary weighting = weightmap * weightmask\n",
    "# purpose is to create a secondary weightmap that can be used to tell the network to focus/ignore on user-selected ROIs\n",
    "\n",
    "def calculate_custom_weightmap(viewer, current_slice=0):\n",
    "    \n",
    "    w_mask = viewer.layers['weightmask'].data[current_slice,...].astype(np.bool)\n",
    "    w_map =  viewer.layers['weightmaps'].data[current_slice,...]   \n",
    "    cust_wmap = w_map*w_mask\n",
    "        \n",
    "    #viewer.add_image(cust_wmap, name='custom weightmap', colormap='plasma', visible=True) # by having this here we generate a new custwm image each time one is generated instead of adding to stack\n",
    "    \n",
    "    #cust_wmap += 1.   \n",
    "    #cust_wmap[w_mask] = 1. #is this necessary? not at the moment\n",
    "    \n",
    "    viewer.layers['custom weightmap'].data[current_slice,...] = cust_wmap.astype(np.float32) # need this line to \n",
    "    viewer.layers['custom weightmap'].contrast_limits = (np.min(cust_wmap), np.max(cust_wmap))\n",
    "    viewer.layers['custom weightmap'].visible = True\n",
    "    \n",
    "    return cust_wmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow_shrink_label(viewer, grow=True, n_iter=1): #by editing the number of iterations i can edit the size of growshrink\n",
    "    # get the current image \n",
    "    current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "    current_labels = viewer.layers['labels'].data[current_slice,...] #label as in image\n",
    "            \n",
    "    cursor_coords = [int(p) for p in viewer.layers[viewer.active_layer].position]\n",
    "    labelled, _ = ndimage.label(current_labels.astype(np.bool)) #each obj in label image is labelled\n",
    "    real_label = current_labels[cursor_coords[0], cursor_coords[1]] #xy cursor coords in current label image\n",
    "    \n",
    "    if real_label < 1: return\n",
    "    \n",
    "    mask = labelled == labelled[cursor_coords[0], cursor_coords[1]] #assigning mask as labelled image with only xy of specific cell\n",
    "    if grow:\n",
    "        mask = ndimage.morphology.binary_dilation(mask, iterations=n_iter)   \n",
    "    else:\n",
    "        current_labels[mask] = 0\n",
    "        mask = ndimage.morphology.binary_erosion(mask, iterations=n_iter)\n",
    "    current_labels[mask] = real_label\n",
    "    viewer.layers['labels'].data[current_slice,...] = current_labels\n",
    "    viewer.layers['labels']._set_view_slice()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cells(viewer):\n",
    "    current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "    mask = viewer.layers['labels'].data[current_slice,...].astype(np.bool) \n",
    "    labelled, n_labels = ndimage.label(mask)\n",
    "       \n",
    "    #print('number of labels/cells in displayed mask is:', n_labels)\n",
    "    stat_file = os.path.join(DATA_PATH, 'stats.csv')\n",
    "    \n",
    "    i=0\n",
    "    df=pd.DataFrame(data=[0], index=[i], columns=['number of cells'])\n",
    "    \n",
    "    for i in range(viewer.layers['labels'].data.shape[0]):\n",
    "        current_slice = i\n",
    "        mask = viewer.layers['labels'].data[current_slice,...].astype(np.bool) \n",
    "        labelled, n_labels = ndimage.label(mask)\n",
    "            \n",
    "        df.loc[i] = n_labels\n",
    "        df.to_csv(stat_file, index=False)\n",
    "    print(df)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_holes(viewer):\n",
    "    current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "    current_labels = viewer.layers['labels'].data[current_slice,...] #label as in image\n",
    "            \n",
    "    cursor_coords = [int(p) for p in viewer.layers[viewer.active_layer].position]\n",
    "    labelled, _ = ndimage.label(current_labels.astype(np.bool)) #each obj in label image is labelled\n",
    "    real_label = current_labels[cursor_coords[0], cursor_coords[1]] #xy cursor coords in current label image\n",
    "    \n",
    "    if real_label < 1: return\n",
    "    \n",
    "    mask = labelled == labelled[cursor_coords[0], cursor_coords[1]] #assigning mask as labelled image with only xy of specific cell\n",
    "    mask = ndimage.morphology.binary_fill_holes(mask) \n",
    "    current_labels[mask] = real_label\n",
    "    viewer.layers['labels'].data[current_slice,...] = current_labels\n",
    "    viewer.layers['labels']._set_view_slice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_cell_mask(viewer):  #by editing the number of iterations i can edit the size of growshrink\n",
    "    # get the current image \n",
    "    current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "    current_labels = viewer.layers['labels'].data[current_slice,...] #label as in image\n",
    "    \n",
    "        \n",
    "    cursor_coords = [int(p) for p in viewer.layers[viewer.active_layer].position]\n",
    "    labelled, _ = ndimage.label(current_labels.astype(np.bool)) #each obj in label image is labelled\n",
    "    real_label = current_labels[cursor_coords[0], cursor_coords[1]] #xy cursor coords in current label image\n",
    "    \n",
    "    if real_label < 1: return\n",
    "    \n",
    "    mask = labelled == labelled[cursor_coords[0], cursor_coords[1]] #assigning mask as labelled image with only xy of specific cell\n",
    "    #print(mask) # we want this image mask here saved as current labels\n",
    "    \n",
    "    current_labels = mask    \n",
    "    #current_labels[mask] = real_label\n",
    "    viewer.layers['labels'].data[current_slice,...] = current_labels\n",
    "    viewer.layers['labels']._set_view_slice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# start napari\n",
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer()\n",
    "    \n",
    "    if Channels.GFP in data:\n",
    "        gfp = normalize_images(data[Channels.GFP]['data'])\n",
    "        viewer.add_image(gfp, name='GFP', colormap='green', contrast_limits=(0.,1.))\n",
    "        \n",
    "    if Channels.RFP in data:\n",
    "        rfp = normalize_images(data[Channels.RFP]['data'])\n",
    "        viewer.add_image(rfp, name='RFP', colormap='magenta', contrast_limits=(0.,1.))\n",
    "        viewer.layers['RFP'].blending = 'additive'\n",
    "        \n",
    "    if Channels.PHASE in data:\n",
    "        phase = normalize_images(data[Channels.PHASE]['data'])\n",
    "        viewer.add_image(phase, name='Phase', colormap='gray')\n",
    "    \n",
    "    if Channels.WEIGHTS in data:\n",
    "        weightmaps = data[Channels.WEIGHTS]['data']\n",
    "        viewer.add_image(weightmaps, name='weightmaps', colormap='plasma', visible=False)\n",
    "        \n",
    "    if Channels.WEIGHTS in data:\n",
    "        cust_wmap = data[Channels.WEIGHTS]['data']\n",
    "        viewer.add_image(cust_wmap, name='custom weightmap', colormap='plasma', visible=False)\n",
    "    \n",
    "    viewer.add_labels(seg, name='labels')\n",
    "    viewer.layers['labels'].opacity = 0.4\n",
    "    viewer.layers['weightmaps'].blending = 'additive'\n",
    "    \n",
    "    weight_mask = np.ones(data[Channels.WEIGHTS]['data'].shape, dtype=np.uint8)\n",
    "    #cust_wmap = np.ones(data[Channels.WEIGHTS]['data'].shape, dtype=np.uint8)\n",
    "    viewer.add_labels(weight_mask, name='weightmask', visible=False)\n",
    "    #viewer.add_image(cust_wmap, name='custom weightmap', colormap='plasma', visible=False)\n",
    "\n",
    "    @viewer.bind_key('/') #double command\n",
    "    def k_save_labels(viewer):\n",
    "        save_labels(viewer)  #need to change the (viewer) bit to save all images   \n",
    "        \n",
    "    @viewer.bind_key('s')\n",
    "    def k_save_all_labels(viewer):\n",
    "        save_all_labels(viewer)\n",
    "        \n",
    "    @viewer.bind_key('n')\n",
    "    def k_count_cells(viewer):\n",
    "        count_cells(viewer)\n",
    "        \n",
    "    @viewer.bind_key('w')\n",
    "    def k_calculate_weightmaps(viewer):\n",
    "        current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "        calculate_weightmaps(viewer, current_slice=current_slice)\n",
    "        ## calculate cust_ here?\n",
    "        \n",
    "    @viewer.bind_key('q')\n",
    "    def k_calculate_custom_weightmap(viewer):\n",
    "        current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "        calculate_custom_weightmap(viewer, current_slice=current_slice)\n",
    "        \n",
    "    @viewer.bind_key('<')\n",
    "    def k_shrink_label(viewer):\n",
    "        print('shrink label')\n",
    "        grow_shrink_label(viewer, grow=False)\n",
    "    \n",
    "    @viewer.bind_key('>') \n",
    "    def k_grow_label(viewer):\n",
    "        print('grow label')\n",
    "        grow_shrink_label(viewer, grow=True)\n",
    "        \n",
    "    @viewer.bind_key('c') #clear\n",
    "    def k_single_cell(viewer):\n",
    "        print('select cell')\n",
    "        single_cell_mask(viewer)\n",
    "        \n",
    "    @viewer.bind_key('h') #fill holes in cell masks\n",
    "    def k_fill_holes(viewer):\n",
    "        print('filling holes in cell mask')\n",
    "        fill_holes(viewer) \n",
    "    \n",
    "    @viewer.bind_key('o')\n",
    "    def k_output(viewer):\n",
    "        print('Output all with metadata')\n",
    "                \n",
    "        for i in range(viewer.layers['weightmaps'].data.shape[0]):\n",
    "            \n",
    "            if np.sum(viewer.layers['weightmaps'].data[i,...]) == 0: # get rid of this condition to calculate weightmaps afresh regardless?\n",
    "                print(f'Weightmap {i} is empty. Calculating...')\n",
    "                wmap = calculate_weightmaps(viewer, current_slice=i)\n",
    "                weight_folder = os.path.join(DATA_PATH, data[Channels.WEIGHTS]['sets'][i], 'weights')\n",
    "                weight_fn = data[Channels.WEIGHTS]['files'][i]\n",
    "                print(weight_folder, weight_fn)\n",
    "                make_folder(weight_folder)\n",
    "                io.imsave(os.path.join(weight_folder, weight_fn), wmap.astype(np.float32))\n",
    "          \n",
    "                #write out cust_weight_map too\n",
    "                \n",
    "                cust_wmap = calculate_custom_weightmap(viewer, current_slice=i)\n",
    "                cust_weight_folder = os.path.join(DATA_PATH, data[Channels.WEIGHTS]['sets'][i], 'custom_weights')       \n",
    "                #os.path.join((data[Channels.WEIGHTS]['files'][i][:+]),'.custom.tif')\n",
    "                cust_weight_fn = data[Channels.WEIGHTS]['files'][i] ##add custom to this fn!!!!!!!!!!!! or do i want to keep fn as before for forward compatability?\n",
    "                print(cust_weight_folder, cust_weight_fn)\n",
    "                make_folder(cust_weight_folder)\n",
    "                io.imsave(os.path.join(cust_weight_folder, cust_weight_fn), cust_wmap.astype(np.float32))\n",
    "                \n",
    "                ## adding save out of the weight masks\n",
    "                w_mask = viewer.layers['weightmask'].data[i,...].astype(np.bool)                \n",
    "                weight_mask_folder = os.path.join(DATA_PATH, data[Channels.WEIGHTS]['sets'][i], 'weight_masks')\n",
    "                weight_mask_fn = data[Channels.MASK]['files'][i] ##add weight to fn\n",
    "                print(weight_mask_folder, weight_mask_fn)\n",
    "                make_folder(weight_mask_folder)\n",
    "                io.imsave(os.path.join(weight_mask_folder, weight_mask_fn), w_mask.astype(np.float32))\n",
    "                \n",
    "                \n",
    "        # write out a JSON file with the data\n",
    "        jfn = os.path.join(DATA_PATH, 'training_metadata.json')\n",
    "        jdata = {}\n",
    "        for channel in data.keys():\n",
    "            jdata[channel.name.lower()] = data[channel]['path']\n",
    "            \n",
    "        with open(jfn, 'w') as json_file:\n",
    "            json.dump(jdata, json_file, indent=2, separators=(',', ': '))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert segmentation output labels to multichannel stacks\n",
    "\n",
    "# p = '/Users/arl/Dropbox/Data/TrainingData/set12'\n",
    "# files = [f for f in os.listdir(os.path.join(p,'labels')) if f.endswith('.tif')]\n",
    "# for f in files:\n",
    "#     mask = io.imread(os.path.join(p, 'labels', f))\n",
    "#     print(mask.shape)\n",
    "#     gfp = mask==1\n",
    "#     rfp = mask==2\n",
    "#     new_mask = np.stack([gfp, rfp], axis=0)\n",
    "#     io.imsave(os.path.join(p,f), new_mask.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:napari]",
   "language": "python",
   "name": "conda-env-napari-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
