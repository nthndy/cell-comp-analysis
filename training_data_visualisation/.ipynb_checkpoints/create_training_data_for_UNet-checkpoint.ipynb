{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating TFRecord files for UNet-based segmentation\n",
    "\n",
    "U-Net: Convolutional Networks for Biomedical Image Segmentation  \n",
    "Olaf Ronneberger, Philipp Fischer and Thomas Brox  \n",
    "http://arxiv.org/abs/1505.04597\n",
    "\n",
    "\n",
    "### DATA ORGANISATION\n",
    "\n",
    "The image list is used like this:\n",
    "\n",
    "```json\n",
    "images = ['phase','rfp']\n",
    "\n",
    "set1/\n",
    "  phase/\n",
    "    \n",
    "  gfp/\n",
    "    0001_gfp.tif\n",
    "    0002_gfp.tif\n",
    "    ...\n",
    "  rfp/\n",
    "    0001_rfp.tif\n",
    "    0002_rfp.tif\n",
    "  ...\n",
    "  labels/\n",
    "    0001_mask.tif\n",
    "    0002_mask.tif\n",
    "    ...\n",
    "  weights/\n",
    "    0001_weights.tif  # NOTE(arl): these are calculated\n",
    "    0002_weights.tif\n",
    "    ...\n",
    "set2/\n",
    "```\n",
    "\n",
    "### STEPS\n",
    "1. Calculate the weightmaps for the images \n",
    "2. Create the TFRecord file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data filename\n",
    "DATA_PATH = '/home/nathan/data/training/training_data_original/'\n",
    "# NOTE TO SELF (NAT) THINK THE OLD WEIGHT FILES+DIRs NEED TO BE DELETED BEFORE NEW ONES ARE MADE\n",
    "#DATA_PATH = \"/home/nathan/analysis/training/training_data\"\n",
    "WEIGHT_AMPLITUDE = 50.\n",
    "tfrecord_fn = \"SHARC_UNet_v3_w0-\"+str(WEIGHT_AMPLITUDE)+\".tfrecord\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/training_data_visualisation/tifffile.py:2170: UserWarning: failed to import _tifffile.decodepackbits\n",
      "  warnings.warn(\"failed to import %s\" % module_function)\n",
      "/home/nathan/analysis/training_data_visualisation/tifffile.py:2170: UserWarning: failed to import _tifffile.decodelzw\n",
      "  warnings.warn(\"failed to import %s\" % module_function)\n",
      "/home/nathan/analysis/training_data_visualisation/tifffile.py:2170: UserWarning: failed to import _tifffile.unpackints\n",
      "  warnings.warn(\"failed to import %s\" % module_function)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import enum\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions to find files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@enum.unique\n",
    "class Channels(enum.Enum):\n",
    "    BRIGHTFIELD = 0 \n",
    "    GFP = 1\n",
    "    RFP = 2\n",
    "    IRFP = 3\n",
    "    PHASE = 4\n",
    "    WEIGHTS = 98\n",
    "    MASK = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata():\n",
    "    jfile = os.path.join(DATA_PATH, 'training_metadata.json')\n",
    "    with open(jfile, 'r') as json_file:\n",
    "        metadata = json.load(json_file)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metadata = read_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to write out the TFRecord file used by the server to train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tfrecord(pth,\n",
    "                   filename,\n",
    "                   metadata,\n",
    "                   weights_dir_base='weights'):\n",
    "    \n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Tensorflow is not installed.\")\n",
    "        \n",
    "    # NOTE(arl): set the number of output channels as n_input+1, this is a guess though    \n",
    "    # parse the metadata, set the number of output channels by guessing\n",
    "    channels = [Channels[c.upper()] for c in metadata.keys() if c not in ('mask', 'weights')]\n",
    "    print(channels)\n",
    "    num_outputs = 2 # len(channels)+1 # only works for multidimensional masks\n",
    "    \n",
    "    # _int64 is used for numeric values\n",
    "    def _int64_feature(value):\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "    # _bytes is used for string/char values\n",
    "    def _bytes_feature(value):\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    # _floats is used for float values\n",
    "    def _float_feature(value):\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "    def convert_to_mask(truth):\n",
    "        if truth.ndim == 2:\n",
    "            unique_labels = [l for l in np.unique(truth).tolist() if l>0]\n",
    "            print(f'Unique labels in mask: {unique_labels}')\n",
    "            mask = np.zeros(truth.shape, dtype=np.uint8)\n",
    "            for i, label in enumerate(unique_labels):\n",
    "                mask[truth==label] = i+1\n",
    "            return mask\n",
    "        \n",
    "        # otherwise we have a multidimensional mask\n",
    "        mask = np.zeros(truth.shape[1:], dtype=np.uint8)\n",
    "        unique_labels = [i+1 for i in range(truth.shape[0])]\n",
    "        print(f'Unique labels in mask: {unique_labels}')\n",
    "        for i, label in enumerate(unique_labels):\n",
    "            mask[truth[i,...]>0] = label\n",
    "            mask[truth[i,...]>0] = label\n",
    "        return mask\n",
    "    \n",
    "    # set up the writer\n",
    "    #writer = tf.python_io.TFRecordWriter(os.path.join(pth, filename))\n",
    "    writer = tf.io.TFRecordWriter(os.path.join(pth, filename))\n",
    "\n",
    "\n",
    "    for i in range(len(metadata['mask'])):\n",
    "        \n",
    "        # get the image data, remove any singleton dimensions \n",
    "        print(i)\n",
    "        for c in channels:\n",
    "            print(c.name.lower())\n",
    "\n",
    "            #i_data = np.stack([io.imread(os.path.join(DATA_PATH, metadata[c.name.lower()[i]]))], axis=-1)\n",
    "            i_data = np.stack([io.imread(os.path.join(DATA_PATH, metadata[c.name.lower()][i])) for c in channels], axis=-1)\n",
    "        \n",
    "        # get the label data \n",
    "        l_data = convert_to_mask(io.imread(os.path.join(DATA_PATH, metadata['mask'][i])))\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.imshow(l_data)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "        # get the weights data\n",
    "        w_data = io.imread(os.path.join(DATA_PATH, metadata['weights'][i])).astype(np.float32)\n",
    "\n",
    "        print(f'Input: {str((i_data.shape, i_data.dtype))}')\n",
    "        print(f'Output: {str((l_data.shape[0], l_data.shape[1], num_outputs))}')\n",
    "\n",
    "        # set up TF feature dict\n",
    "        feature = {'train/image/image': _bytes_feature(i_data.tostring()),\n",
    "                   'train/image/width': _int64_feature(i_data.shape[1]),\n",
    "                   'train/image/height': _int64_feature(i_data.shape[0]),\n",
    "                   'train/image/depth': _int64_feature(i_data.shape[-1]),\n",
    "                   'train/label/image': _bytes_feature(l_data.tostring()),\n",
    "                   'train/label/width': _int64_feature(l_data.shape[1]),\n",
    "                   'train/label/height': _int64_feature(l_data.shape[0]),\n",
    "                   'train/label/depth': _int64_feature(num_outputs),\n",
    "                   'train/weight/image': _bytes_feature(w_data.tostring()),\n",
    "                   'train/weight/width': _int64_feature(w_data.shape[1]),\n",
    "                   'train/weight/height': _int64_feature(w_data.shape[0]),\n",
    "                   'train/weight/depth': _int64_feature(1)}\n",
    "\n",
    "        features = tf.train.Features(feature=feature)\n",
    "        example = tf.train.Example(features=features)\n",
    "\n",
    "        # write out the serialized features\n",
    "        writer.write(example.SerializeToString())\n",
    "\n",
    "    # close up shop\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write out the TFRecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Channels.PHASE: 4>, <Channels.GFP: 1>, <Channels.RFP: 2>]\n",
      "0\n",
      "phase\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'parse_kwargs' from 'tifffile' (/home/nathan/analysis/training_data_visualisation/tifffile.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-826204384d9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrite_tfrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfrecord_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I AM DONE THANK YOU VERY MUCH\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ea94d77dcb4b>\u001b[0m in \u001b[0;36mwrite_tfrecord\u001b[0;34m(pth, filename, metadata, weights_dir_base)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m#i_data = np.stack([io.imread(os.path.join(DATA_PATH, metadata[c.name.lower()[i]]))], axis=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mi_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# get the label data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ea94d77dcb4b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m#i_data = np.stack([io.imread(os.path.join(DATA_PATH, metadata[c.name.lower()[i]]))], axis=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mi_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# get the label data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/btrack/lib/python3.7/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/btrack/lib/python3.7/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugin_funcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplugin_funcs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/btrack/lib/python3.7/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(plugin)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mmodname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugin_module_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         plugin_module = __import__('skimage.io._plugins.' + modname,\n\u001b[0;32m--> 297\u001b[0;31m                                    fromlist=[modname])\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0mprovides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugin_provides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/btrack/lib/python3.7/site-packages/skimage/io/_plugins/tifffile_plugin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtifffile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTiffFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimsave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'parse_kwargs' from 'tifffile' (/home/nathan/analysis/training_data_visualisation/tifffile.py)"
     ]
    }
   ],
   "source": [
    "write_tfrecord(DATA_PATH, tfrecord_fn, metadata)\n",
    "print(\"I AM DONE THANK YOU VERY MUCH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btrack",
   "language": "python",
   "name": "btrack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
