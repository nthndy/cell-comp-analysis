{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAPARI visualization of Segmentation and Tracking output\n",
    "\n",
    "You can use this notebook to view, modified and save out training data for UNet models\n",
    "\n",
    "Labels:\n",
    "+ 0 - background \n",
    "+ 1 - GFP/Phase \n",
    "+ 2 - RFP\n",
    "\n",
    "\n",
    "Extra key bindings:\n",
    "+ None yet\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TODO:\n",
    "\n",
    "- (arl): output masks for making training data more easily\n",
    "- (arl): put locations and classification labels onto identified cells\n",
    "- (arl): visualize tracks\n",
    "- (arl): deal with datasets that do not have a segmentation\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "```\n",
    "Authors:\n",
    "- Alan R. Lowe (a.lowe@ucl.ac.uk)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Set up the data path and options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/arl/Dropbox/Data/Giulia/Pos13'\n",
    "PAD_SEGMENTATION = True\n",
    "SHOW_OUTLINES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import enum\n",
    "import json\n",
    "import napari\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.ndimage import binary_erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@enum.unique\n",
    "class Channels(enum.Enum):\n",
    "    BRIGHTFIELD = 0 \n",
    "    GFP = 1\n",
    "    RFP = 2\n",
    "    IRFP = 3\n",
    "    PHASE = 4\n",
    "    WEIGHTS = 98\n",
    "    MASK = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleOctopusLiteLoader(object):\n",
    "    \"\"\" SimpleOctopusLiteLoader \n",
    "    \n",
    "    A simple class to load OctopusLite data from a directory. \n",
    "    Caches data once it is loaded to prevent excesive io to \n",
    "    the data server.\n",
    "    \n",
    "    Can directly address fluorescence channels using the\n",
    "    `Channels` enumerator:\n",
    "    \n",
    "        Channels.BRIGHTFIELD \n",
    "        Channels.GFP\n",
    "        Channels.RFP \n",
    "        Channels.IRFP\n",
    "        \n",
    "    Usage:\n",
    "        octopus = SimpleOctopusLiteLoader('/path/to/your/data')\n",
    "        gfp = octopus[Channels.GFP]\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self._files = {}\n",
    "        self._data = {}\n",
    "        \n",
    "        # parse the files\n",
    "        self._parse_files()\n",
    "        \n",
    "        self._shape = (0,1352,1688)\n",
    "        \n",
    "    def __contains__(self, channel):\n",
    "        return channel in self.channels\n",
    "        \n",
    "    @property \n",
    "    def channels(self):\n",
    "        return list(self._files.keys())\n",
    "    \n",
    "    @property \n",
    "    def shape(self):\n",
    "        return self._shape\n",
    "    \n",
    "    def channel_name_from_index(self, channel_index):\n",
    "        return Channels(int(channel_index))\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, channel_name):\n",
    "        assert(channel_name in self.channels)\n",
    "        \n",
    "        if channel_name not in self._data:\n",
    "            self._load_channel(channel_name)\n",
    "            \n",
    "        return self._data[channel_name]\n",
    "    \n",
    "    \n",
    "    def _parse_files(self):\n",
    "        \"\"\" parse out the files from the folder \"\"\"\n",
    "        files = [f for f in os.listdir(self.path) if f.endswith('.tif')]\n",
    "    \n",
    "        def parse_filename(fn):\n",
    "            pattern = \"img_channel([0-9]+)_position([0-9]+)_time([0-9]+)_z([0-9]+)\"\n",
    "            params = re.match(pattern, fn)\n",
    "            return self.channel_name_from_index(params.group(1)), params.group(3)\n",
    "        \n",
    "        channels = {k:[] for k in Channels}\n",
    "    \n",
    "        # parse the files and sort them \n",
    "        for f in files:\n",
    "            channel, time = parse_filename(f)\n",
    "            channels[channel].append(f)\n",
    "            \n",
    "        for channel in channels.keys():\n",
    "            channels[channel].sort(key=lambda f: parse_filename(f)[1])\n",
    "            \n",
    "        # remove any channels that are empty\n",
    "        self._files = {k:v for k, v in channels.items() if v}\n",
    "    \n",
    "    def _load_channel(self, channel_name):\n",
    "        assert(channel_name in self.channels)\n",
    "\n",
    "        \n",
    "        def load_image(fn):\n",
    "            return io.imread(os.path.join(self.path, fn))\n",
    "        \n",
    "         # load the first image\n",
    "        im = load_image(self._files[channel_name][0])\n",
    "        \n",
    "        # preload the stack\n",
    "        stack = np.zeros((len(self._files[channel_name]),)+im.shape, dtype=im.dtype)\n",
    "        self._shape = stack.shape\n",
    "        \n",
    "        print('Loading: {} --> {} ({})...'.format(channel_name, stack.shape, stack.dtype))\n",
    "        \n",
    "        stack[0,...] = im\n",
    "        for i in range(1, stack.shape[0]):\n",
    "            stack[i,...] = load_image(self._files[channel_name][i])\n",
    "            \n",
    "        self._data[channel_name] = stack\n",
    "\n",
    "        \n",
    "    def clear_cache(self, channel_name):\n",
    "        print('Warning! You are clearing the cache for: {}'.format(channel_name))\n",
    "        self._data[channel_name] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_folder(foldername):\n",
    "#     if os.path.exists(foldername):\n",
    "#         return\n",
    "#     os.mkdir(foldername)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_segmentation(path):\n",
    "    \"\"\" load the segmentation \"\"\"\n",
    "    segmentations = [z for z in os.listdir(path) if z.startswith('segmented') and z.endswith('.zip')]\n",
    "    segmentations.sort(key=lambda z: os.path.getctime(os.path.join(path,z)), reverse=True)\n",
    "    \n",
    "    segmentation = []\n",
    "    \n",
    "    if SHOW_OUTLINES:\n",
    "        outline = lambda s: s * np.logical_xor(binary_erosion(s.astype(np.bool), iterations=2), s.astype(np.bool))\n",
    "    else:\n",
    "        outline = lambda s: s\n",
    "    \n",
    "    with ZipFile(os.path.join(path, segmentations[0])) as segzip:\n",
    "        seg_files = sorted(segzip.namelist(), key=lambda f:int(f[2:-4]))\n",
    "        segmentation = [outline(io.imread(segzip.open(s))) for s in seg_files]\n",
    "        \n",
    "    return np.stack(segmentation, axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SimpleOctopusLiteLoader(DATA_PATH)\n",
    "segmentation = load_segmentation(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PAD_SEGMENTATION:\n",
    "    # pad the segmentation\n",
    "    px, py = int((data.shape[1]-segmentation.shape[1])/2), int((data.shape[2]-segmentation.shape[2])/2)\n",
    "    seg = np.pad(segmentation, ((0,0), (px,px), (py,py)), constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(stack):\n",
    "    normed = stack.astype(np.float32)\n",
    "    for i in range(stack.shape[0]):\n",
    "        # normed[i,...] = (normed[i,...]-np.mean(normed[i,...])) / np.std(normed[i,...])\n",
    "        c = normed[i,...]\n",
    "        p_lo = np.percentile(c,5)\n",
    "        p_hi = np.percentile(c,99.5)\n",
    "        normed[i,...] = np.clip((c - p_lo) / p_hi, 0., 1.)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_boxes(seg):\n",
    "    lbl, nlbl = ndimage.label(seg)\n",
    "    class_label, _, minxy, maxxy = ndimage.extrema(seg, lbl, index=np.arange(1, nlbl+1))\n",
    "    return class_label, minxy, maxxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: Channels.BRIGHTFIELD --> (31, 1352, 1688) (uint8)...\n",
      "Loading: Channels.GFP --> (31, 1352, 1688) (uint8)...\n",
      "Loading: Channels.RFP --> (31, 1352, 1688) (uint8)...\n"
     ]
    }
   ],
   "source": [
    "# start napari\n",
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer()\n",
    "    \n",
    "    if Channels.BRIGHTFIELD in data:\n",
    "        phase = normalize_images(data[Channels.BRIGHTFIELD])\n",
    "        viewer.add_image(phase, name='Brightfield', colormap='gray')\n",
    "        \n",
    "    if Channels.PHASE in data:\n",
    "        phase = normalize_images(data[Channels.PHASE])\n",
    "        viewer.add_image(phase, name='Phase', colormap='gray')\n",
    "    \n",
    "    if Channels.GFP in data:\n",
    "        gfp = normalize_images(data[Channels.GFP])\n",
    "        viewer.add_image(gfp, name='GFP', colormap='green', contrast_limits=(0.,1.))\n",
    "        viewer.layers['GFP'].blending = 'additive'\n",
    "        \n",
    "    if Channels.RFP in data:\n",
    "        rfp = normalize_images(data[Channels.RFP])\n",
    "        viewer.add_image(rfp, name='RFP', colormap='magenta', contrast_limits=(0.,1.))\n",
    "        viewer.layers['RFP'].blending = 'additive'    \n",
    "    \n",
    "    viewer.add_labels(seg, name='labels', opacity=1.0)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:napari]",
   "language": "python",
   "name": "conda-env-napari-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
