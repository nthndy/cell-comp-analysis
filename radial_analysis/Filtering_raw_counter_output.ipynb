{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the output from Cumulative event counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook just for compiling raw listed cell/event counter data as heatmaps only using focal apoptoses that stretch back in time for a certain duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, glob, re, os, json, shutil\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import render, dataio\n",
    "import calculate_radial_analysis as calculate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering individual apoptoses based on length\n",
    "\n",
    "Doing this because there is an notable increase in probability 26 hours prior but not every apoptotic mutant will exist 26 hours before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/home/nathan/data/results/radial_analysis_output/follow/raw_lists/800.800/canon/800.800'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "apop_IDs = [fn.split('_N_cells')[0] for fn in os.listdir(source_dir) if 'N_cells' in fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/nathan/data/kraken/h2b/giulia/apoptosis_information/expt_movie_length.json') as json_file:\n",
    "    movie_time_range = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/nathan/data/kraken/h2b/giulia/apoptosis_information/scr_apop_dict.json') as json_file:\n",
    "    apop_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter list of focal apoptoses based on length\n",
    "\n",
    "Only want focal apoptoses that extend back 21 hours i.e. 2160 minutes = 315 frames\n",
    "\n",
    "*** a more accurate measure is excluding the last bin of 80 frames (800/10) so going back 320 frames ***\n",
    "\n",
    "So I only want cells that have existed for 315 or greater frames, for this I need to load the tracks of each of the individual apop IDs and check if len(track) > 315 and if t(apop) > 315 (mutually verifiable)\n",
    "\n",
    "Could refine this criteria later as there will be many that don't extend back this far yet still are >18 or >16 hours (still areas of interest) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading apoptotic cell track information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "previous_h5 = ''\n",
    "valid_apops = []\n",
    "hdf5_root_dir = '/home/nathan/data/kraken/h2b/giulia/'\n",
    "for ID in tqdm(apop_dict):\n",
    "    expt = ID.split('_')[0]\n",
    "    pos = ID.split('_')[1]\n",
    "    cell_ID = ID.split('_')[2]\n",
    "    ### load HDF5\n",
    "    h5_path = os.path.join(hdf5_root_dir, expt, pos, pos+'_aligned', 'HDF/segmented.hdf5')\n",
    "    if h5_path != previous_h5:\n",
    "        wt_cells, scr_cells, all_cells = dataio.load_tracking_data(h5_path)\n",
    "    cell = [cell for cell in scr_cells if cell.ID == -int(cell_ID)][0]\n",
    "    ### if there is enough time prior to apoptosis and if the track exists for that time period\n",
    "    if apop_dict[ID] > 320:\n",
    "        if len(cell) > 320:\n",
    "            valid_apops.append(ID)\n",
    "            print(ID, len(cell), apop_dict[ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(valid_apops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_apops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make dict out of new list of apop_IDs\n",
    "valid_apop_dict = {}\n",
    "for ID in valid_apops:\n",
    "    valid_apop_dict[ID] = apop_dict[ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_apop_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### saving out list of valid apoptoses that stretch back 21 hours\n",
    "with open('/home/nathan/data/kraken/h2b/giulia/apoptosis_information/21hr_accurate_apop_dict.json', 'w') as file:\n",
    "    json.dump(valid_apop_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading valid apop_dict\n",
    "with open('/home/nathan/data/kraken/h2b/giulia/apoptosis_information/21hr_apop_dict.json', 'r') as file:\n",
    "    valid_apop_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_apop_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making new cumulative plot out of filtered apop IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new source directory containing only apop IDs of relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### move only apop IDs of interest into new directory and rename with focal time\n",
    "for fn in natsorted(os.listdir('/home/nathan/data/results/radial_analysis_output/follow/raw_lists/800.800/canon/800.800')):\n",
    "    ID = fn.split('_N_')[0]\n",
    "    ID = ID.replace('Scr-','') + '_RFP' ### renaming filename apop ID as dict compatible\n",
    "    if ID in valid_apop_dict:\n",
    "        new_fn = fn.replace('.', '_focal_t_{}.'.format(str(valid_apop_dict[ID])))\n",
    "        shutil.copyfile(os.path.join('/home/nathan/data/results/radial_analysis_output/follow/raw_lists/800.800/canon/800.800', fn),os.path.join('/home/nathan/data/results/radial_analysis_output/follow/raw_lists/800.800/canon/21_hours_accurate', new_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile into numpy arrays of N_cells, N_events, P_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for config in ['800.800.10', '800.800.20']:#['800.800.6', '600.600.8', '600.600.6', '500.500.6' '1000.1000.10', '1000.1000.6']:\n",
    "    save_parent_dir = '/home/nathan/data/results/radial_analysis_output/follow/cumulative_plots/21_hours_accurate'\n",
    "    radius = int(config.split('.')[0])\n",
    "    t_range = int(config.split('.')[1])\n",
    "    num_bins = int(config.split('.')[2])\n",
    "    ### canon\n",
    "    raw_files_dir = os.path.join('/home/nathan/data/results/radial_analysis_output/follow/raw_lists/800.800/canon/21_hours_accurate')\n",
    "    N_cells, N_events, P_events = render.cumulative_kymo_compiler(raw_files_dir, radius, t_range, num_bins)\n",
    "    limit = np.amax(P_events)\n",
    "    N = int(len(os.listdir(raw_files_dir))/2)\n",
    "\n",
    "    ### control \n",
    "    # raw_files_dir = os.path.join('/home/nathan/data/kraken/h2b/giulia/radial_analysis_output/follow/raw_lists/1600.1600/control_ninety_ten')\n",
    "    # N_cells_c, N_events_c, P_events_c = render.cumulative_kymo_compiler(raw_files_dir, radius, t_range, num_bins)\n",
    "    # limit_c = np.amax(P_events_c)\n",
    "    # N_c = int(len(os.listdir(raw_files_dir))/2)\n",
    "\n",
    "    ### save out raw arrays for coeff var\n",
    "    fn = os.path.join(save_parent_dir,'arrays/21_hours_accurate/canon_21_hours_accurate_N_cell_N_event_P_event_{}.{}.{}.npz'.format(radius,t_range, num_bins))\n",
    "    if not os.path.exists(os.path.dirname(fn)):\n",
    "        os.makedirs(os.path.dirname(fn))\n",
    "    # fn_c = os.path.join(save_parent_dir, 'arrays/control_ninety_ten_N_cell_N_event_P_event_{}.{}.{}.npz'.format(radius,t_range, num_bins))\n",
    "    # if not os.path.exists(os.path.dirname(fn_c)):\n",
    "    #     os.makedirs(os.path.dirname(fn_c))\n",
    "    np.savez(fn, N_cells, N_events, P_events)\n",
    "    #np.savez(fn_c, N_cells_c, N_events_c, P_events_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or load from previously compiles .npz stacks of N_cells, N_events, P_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius, t_range, num_bins = 800, 800, 10\n",
    "### load npz\n",
    "with np.load('/home/nathan/data/results/radial_analysis_output/follow/cumulative_plots/arrays/21_hours_accurate/canon_21_hours_accurate_N_cell_N_event_P_event_{}.{}.{}.npz'.format(radius, t_range, num_bins)) as data:\n",
    "    N_cells = data['arr_0']\n",
    "    N_events = data['arr_1']\n",
    "    P_events = data['arr_2']\n",
    "with np.load('/home/nathan/data/results/radial_analysis_output/follow/cumulative_plots/arrays/control_N_cell_N_event_P_event_{}.{}.{}.npz'.format(radius, t_range, num_bins)) as data:\n",
    "    N_cells_c = data['arr_0']\n",
    "    N_events_c = data['arr_1']\n",
    "    P_events_c = data['arr_2']\n",
    "N_c = 10491\n",
    "N = len(valid_apops)# 1839\n",
    "limit_c = np.amax(P_events_c)\n",
    "limit = np.amax(P_events)\n",
    "cbar_lim = tuple((0, max(limit_c, limit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_parent_dir = '/home/nathan/data/results/radial_analysis_output/follow/cumulative_plots/plots/21_hours_accurate_{}.{}.{}/'.format(radius, t_range, num_bins)\n",
    "render.MEGAPLOT(N_cells, N_events, P_events, N_cells_c, N_events_c, P_events_c, N, N_c, limit, limit_c, cbar_lim, radius, t_range, num_bins, save_parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating over several different scales with bulk output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config in ['200.200.10', '400.400.10', '800.800.10', '600.600.20', '800.800.20']:\n",
    "    radius = int(config.split('.')[0])\n",
    "    t_range = int(config.split('.')[1])\n",
    "    num_bins = int(config.split('.')[2])\n",
    "    print('starting dimensions radius, t_range, num_bins:',radius, t_range, num_bins)\n",
    "    save_parent_dir = '/home/nathan/data/kraken/h2b/giulia/radial_analysis_output/follow/cumulative_plots/plots/210804_{}.{}.{}'.format(radius, t_range, num_bins)\n",
    "    ### load npz\n",
    "    with np.load('/home/nathan/data/kraken/h2b/giulia/radial_analysis_output/follow/cumulative_plots/arrays/canon_N_cell_N_event_P_event_{}.{}.{}.npz'.format(radius, t_range, num_bins, radius, t_range, num_bins)) as data:\n",
    "        N_cells = data['arr_0']\n",
    "        N_events = data['arr_1']\n",
    "        P_events = data['arr_2']\n",
    "    with np.load('/home/nathan/data/kraken/h2b/giulia/radial_analysis_output/follow/cumulative_plots/arrays/control_N_cell_N_event_P_event_{}.{}.{}.npz'.format(radius, t_range, num_bins, radius, t_range, num_bins)) as data:\n",
    "        N_cells_c = data['arr_0']\n",
    "        N_events_c = data['arr_1']\n",
    "        P_events_c = data['arr_2']\n",
    "    N_c = 10491\n",
    "    N = 1839\n",
    "    limit_c = np.amax(P_events_c)\n",
    "    limit = np.amax(P_events)\n",
    "    cbar_lim = tuple((0, max(limit_c, limit)))\n",
    "    render.MEGAPLOT(N_cells, N_events, P_events, N_cells_c, N_events_c, P_events_c, N, N_c, limit, limit_c, cbar_lim, radius, t_range, num_bins, save_parent_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
